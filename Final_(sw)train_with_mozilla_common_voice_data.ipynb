{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f79d99ef"
      },
      "source": [
        "# Train a üê∏ Kiswahili STT model with Mozilla Common Voice data üí´\n",
        "\n",
        "üëã Hello and welcome to this Mozilla Common Voice and Coqui (üê∏) STT Coding Challenge\n",
        "\n",
        "This notebook shows a **typical workflow** for **training** and **testing** an üê∏ STT model on Kiswahili data from Mozilla Common Voice.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Download Mozilla Common Voice data (pre-formatted for üê∏ STT)\n",
        "2. Configure the training and testing runs\n",
        "3. Train a new model\n",
        "4. Test the model and display its performance\n",
        "\n",
        "So, let's jump right in!\n"
      ],
      "id": "f79d99ef"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "IgrSmlgkgVOB"
      },
      "id": "IgrSmlgkgVOB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "\n",
        "!sudo apt-get install python3.7\n",
        "\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "\n",
        "!sudo update-alternatives --config python3\n",
        "\n",
        "!apt-get install python3-pip python3.7-distutils"
      ],
      "metadata": {
        "id": "LGmNNjdNHqkH"
      },
      "id": "LGmNNjdNHqkH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "tHqtCOtEQ9f0"
      },
      "id": "tHqtCOtEQ9f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa2aec78"
      },
      "source": [
        "## Install Coqui STT\n",
        "! pip install -U pip\n",
        "! pip install coqui_stt_training\n",
        "## Install opus tools\n",
        "! apt-get install libopusfile0 libopus-dev libopusfile-dev"
      ],
      "id": "fa2aec78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Install Coqui STT\n",
        "# dependencies\n",
        "! sudo apt-get install sox libsox-fmt-mp3 libopusfile0 libopus-dev libopusfile-dev libsox-fmt-all libssl-doc -y\n",
        "! pip install --upgrade pip\n",
        "# the Coqui training package\n",
        "! pip install coqui_stt_training==1.4.0\n",
        "! pip uninstall -y tensorflow; pip install \"tensorflow-gpu==1.15\"\n",
        "# code with importer scripts\n",
        "# ! git clone --depth=1 https://github.com/coqui-ai/STT.git"
      ],
      "metadata": {
        "id": "SfKHCbjSoJtt"
      },
      "id": "SfKHCbjSoJtt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from coqui_stt_training.util.config import initialize_globals_from_args"
      ],
      "metadata": {
        "id": "IYnp5ORsolub"
      },
      "id": "IYnp5ORsolub",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be5fe49c"
      },
      "source": [
        "## ‚úÖ Download & format sample data for Kiswahili\n",
        "\n",
        "**First things first**: we need some data.\n",
        "\n",
        "We're training a Speech-to-Text model, so we want _speech_ and we want _text_. Specificially, we want _transcribed speech_. Let's download some audio and transcripts.\n",
        "\n",
        "To focus on model training, we formatted the Mozilla Common Voice data for you already, and you will find CSV files for `{train,test,dev}.csv` in the data directory.\n",
        "\n",
        "Let's download some data for Kiswahili üòä\n",
        "\n",
        "You can access the pre-formatted data via this Google Drive link (https://drive.google.com/drive/folders/1sEBmonkwNu65w1zIp8PYutI71mBHmdra?usp=sharing)\n",
        "\n",
        "This tutorial assumes that you will add this data to your own Google Drive, so we shall go ahead and have the notebook access the data from there by connecting it to Google Drive.\n",
        "\n",
        "Outside of this tutorial, be sure to check the full Kiswahili dataset as well as all the other language datasets available for STT on Mozilla Common Voice(https://commonvoice.mozilla.org/datasets)\n"
      ],
      "id": "be5fe49c"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "id": "M97edsf1KTND"
      },
      "id": "M97edsf1KTND",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edit the cell below to reflect the directory where you have placed your data."
      ],
      "metadata": {
        "id": "fWC48VbyZSm3"
      },
      "id": "fWC48VbyZSm3"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/Events/swahilipot_hackathon\n"
      ],
      "metadata": {
        "id": "PN6A2FczLLqZ"
      },
      "id": "PN6A2FczLLqZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üëÄ Take a look at the data"
      ],
      "metadata": {
        "id": "J_RnWenPZutL"
      },
      "id": "J_RnWenPZutL"
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "id": "hYw2_jg4Zx6h"
      },
      "id": "hYw2_jg4Zx6h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9dfac21"
      },
      "source": [
        "## ‚úÖ Configure & set hyperparameters\n",
        "\n",
        "Coqui STT comes with a long list of hyperparameters you can tweak. We've set default values, but you will often want to set your own. You can use `initialize_globals_from_args()` to do this.\n",
        "\n",
        "You must **always** configure the paths to your data, and you must **always** configure your alphabet. Additionally, here we show how you can specify the size of hidden layers (`n_hidden`), the number of epochs to train for (`epochs`), and to initialize a new model from scratch (`load_train=\"init\"`).\n",
        "\n",
        "There are many other hyperparameters not included in this tutorial, if you would like to further configure these to boost the performance of your model, be sure to check out the Coqui STT documentation.(https://stt.readthedocs.io/en/latest/index.html)\n",
        "\n",
        "If you're training on a GPU, you can uncomment the (larger) training batch sizes for faster training."
      ],
      "id": "d9dfac21"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d264fdec"
      },
      "source": [
        "from coqui_stt_training.util.config import initialize_globals_from_args\n",
        "\n",
        "initialize_globals_from_args(\n",
        "    train_files=[\"train.csv\"],\n",
        "    dev_files=[\"dev.csv\"],\n",
        "    test_files=[\"test.csv\"],\n",
        "    checkpoint_dir=\"checkpoints/\",\n",
        "    load_train=\"init\",\n",
        "    n_hidden=200,\n",
        "    epochs=1,\n",
        "    beam_width=1,\n",
        "    #train_batch_size=128,\n",
        "    #dev_batch_size=128,\n",
        "    #test_batch_size=128,\n",
        ")"
      ],
      "id": "d264fdec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "799c1425"
      },
      "source": [
        "### üëÄ View all config settings"
      ],
      "id": "799c1425"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03b33d2b"
      },
      "source": [
        "from coqui_stt_training.util.config import Config\n",
        "\n",
        "print(Config.to_json())"
      ],
      "id": "03b33d2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae82fd75"
      },
      "source": [
        "## ‚úÖ Train a new model\n",
        "\n",
        "Let's kick off a training run üöÄüöÄüöÄ (using the configure you set above)."
      ],
      "id": "ae82fd75"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "550a504e"
      },
      "source": [
        "from coqui_stt_training.train import train\n",
        "\n",
        "train()"
      ],
      "id": "550a504e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f6dc959"
      },
      "source": [
        "## ‚úÖ Test the model\n",
        "\n",
        "We made it! üôå\n",
        "\n",
        "Let's kick off the testing run, which displays performance metrics.\n",
        "\n",
        "The settings we used here are for demonstration purposes, so you don't want to deploy this model into production. In this notebook we're focusing on the workflow itself, so it's forgivable üòá\n",
        "\n",
        "You can still train a more State-of-the-Art model by finding better hyperparameters, so go for it üí™"
      ],
      "id": "9f6dc959"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd42bc7a"
      },
      "source": [
        "from coqui_stt_training.evaluate import test\n",
        "\n",
        "test()"
      ],
      "id": "dd42bc7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Submit to this Coding Challenge\n",
        "\n",
        "Once you have a well-performing model, you can go ahead and submit your results in order to stand a chance to win some prizes from the coding challenge. Use this form(https://forms.gle/sfJVDrb6n6HrmYTn8) which will require you to submit 2 screenshots.\n",
        "First one with the hyper-parameters cell from your notebook. This is the first code cell under the 'Configure & set hyperparameters' section. (If the cell contents are long, zoom out and ensure to capture the *ENTIRE* contents of the cell)\n",
        "Second is a screenshot of the results of testing your model. This should be the output from the cell under the 'Test the Model' section. Include only the very *TOP* of the output where the best CER, WER and loss values are visible.\n",
        "\n",
        "Finally, you will also need to manually input these values(WER, CER, loss) in some fields provided in the form.\n",
        "\n",
        "All the best!"
      ],
      "metadata": {
        "id": "yHBAQsGx4yG7"
      },
      "id": "yHBAQsGx4yG7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZwumwM8FKD_"
      },
      "source": [
        "## ‚úÖ Take it further with Mozilla Common Voice\n",
        "\n",
        "We hope you enjoyed this coding challenge!\n",
        "\n",
        "If you want to take your model to the next level, and stand a chance to win USD$ 2000, check out our latest Model and Methods Competition(https://foundation.mozilla.org/en/blog/announcing-our-voices-a-new-competition-by-mozilla-to-fight-bias-in-voice-technology/)"
      ],
      "id": "EZwumwM8FKD_"
    }
  ]
}